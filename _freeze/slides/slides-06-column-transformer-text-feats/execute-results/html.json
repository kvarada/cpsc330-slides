{
  "hash": "c1b990a2bae440f9de92fd64041984fe",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Lecture 6: Column transformer and text features\"\nauthor: \"Varada Kolhatkar\"\ndescription: \"Column transformer and introduction to text features\"\ndescription-short: \"Preprocessing and sklearn pipelines\"\nformat:\n  revealjs:\n    embed-resources: true\n    slide-number: true\n    smaller: true\n    center: true\n    logo: img/UBC-CS-logo.png\n    resources:\n      - data/\n      - img/  \n---\n\n\n## Announcements \n\n- Where to find slides? \n  - https://kvarada.github.io/cpsc330-slides/lecture.html\n- HW3 is due next week Tuesday, Sept 29th, 11:59 pm. \n  - If you've started yet, start now. \n  - You can work in pairs for this assignment. \n\n\n\n# Recap: Preprocessing mistakes\n\n## Data \n\n::: {#9ea4424e .cell execution_count=2}\n``` {.python .cell-code}\nX, y = make_blobs(n_samples=100, centers=3, random_state=12, cluster_std=5) # make synthetic data\nX_train_toy, X_test_toy, y_train_toy, y_test_toy = train_test_split(\n    X, y, random_state=5, test_size=0.4) # split it into training and test sets\n# Visualize the training data\nplt.scatter(X_train_toy[:, 0], X_train_toy[:, 1], label=\"Training set\", s=60)\nplt.scatter(\n    X_test_toy[:, 0], X_test_toy[:, 1], color=mglearn.cm2(1), label=\"Test set\", s=60\n)\nplt.legend(loc=\"upper right\")\n```\n\n::: {.cell-output .cell-output-display}\n![](slides-06-column-transformer-text-feats_files/figure-revealjs/cell-3-output-1.png){}\n:::\n:::\n\n\n## Bad methodology 1\n- What's wrong with scaling data separately? \n\n::: {#bbfbe5bc .cell execution_count=3}\n``` {.python .cell-code}\nscaler = StandardScaler() # Creating a scalert object \nscaler.fit(X_train_toy) # Calling fit on the training data \ntrain_scaled = scaler.transform(\n    X_train_toy\n)  # Transforming the training data using the scaler fit on training data\n\nscaler = StandardScaler()  # Creating a separate object for scaling test data\nscaler.fit(X_test_toy)  # Calling fit on the test data\ntest_scaled = scaler.transform(\n    X_test_toy\n)  # Transforming the test data using the scaler fit on test data\n\nknn = KNeighborsClassifier()\nknn.fit(train_scaled, y_train_toy)\nprint(f\"Training score: {knn.score(train_scaled, y_train_toy):.2f}\")\nprint(f\"Test score: {knn.score(test_scaled, y_test_toy):.2f}\") # misleading scores\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTraining score: 0.63\nTest score: 0.60\n```\n:::\n:::\n\n\n## Scaling train and test data separately\n\n::: {#101f2f08 .cell execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![](slides-06-column-transformer-text-feats_files/figure-revealjs/cell-5-output-1.png){}\n:::\n:::\n\n\n## Bad methodology 2 \n- What's wrong with scaling the data together\n\n::: {#81f0eff4 .cell execution_count=5}\n``` {.python .cell-code}\n# join the train and test sets back together\nXX = np.vstack((X_train_toy, X_test_toy))\n\nscaler = StandardScaler()\nscaler.fit(XX)\nXX_scaled = scaler.transform(XX)\n\nXX_train = XX_scaled[:X_train_toy.shape[0]]\nXX_test = XX_scaled[X_train_toy.shape[0]:]\n\nknn = KNeighborsClassifier()\nknn.fit(XX_train, y_train_toy)\nprint(f\"Training score: {knn.score(XX_train, y_train_toy):.2f}\")  # Misleading score\nprint(f\"Test score: {knn.score(XX_test, y_test_toy):.2f}\")  # Misleading score\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTraining score: 0.63\nTest score: 0.55\n```\n:::\n:::\n\n\n## Bad methodology 3\n\n- What's wrong here? \n\n::: {#d56074a3 .cell execution_count=6}\n``` {.python .cell-code}\nknn = KNeighborsClassifier()\n\nscaler = StandardScaler()\nscaler.fit(X_train_toy)\nX_train_scaled = scaler.transform(X_train_toy)\nX_test_scaled = scaler.transform(X_test_toy)\ncross_val_score(knn, X_train_scaled, y_train_toy)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\narray([0.25      , 0.5       , 0.58333333, 0.58333333, 0.41666667])\n```\n:::\n:::\n\n\n::: {.scroll-container style=\"overflow-y: scroll; height: 500px;\"}\n## Improper preprocessing\n\n::: {#976bd08d .cell execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![](slides-06-column-transformer-text-feats_files/figure-revealjs/cell-8-output-1.png){}\n:::\n:::\n\n\n:::\n\n::: {.scroll-container style=\"overflow-y: scroll; height: 500px;\"}\n## Proper preprocessing\n\n::: {#9a733a99 .cell execution_count=8}\n\n::: {.cell-output .cell-output-display}\n![](slides-06-column-transformer-text-feats_files/figure-revealjs/cell-9-output-1.png){}\n:::\n:::\n\n\n:::\n\n\n## Avoiding Data Leakage\n\n- **Independence from test data:**\n  - We want to ensure the training process remains completely independent of the test data.\n\n- **Role of the validation set**\n  - Use the validation set exclusively for hyperparameter tuning. It should not contribute to the actual training of the model to prevent inadvertent data leakage.\n\n- **Preprocessing pitfalls** \n  - It's a common mistake to violate the golden rule during preprocessing by using information from the validation or test datasets\n\n\n## Recap: `sklearn` Pipelines\n\n- Pipeline is a way to chain multiple steps (e.g., preprocessing + model fitting) into a single workflow.\n- Simplify the code and improves readability.\n- Reduce the risk of data leakage by ensuring proper transformation of the training and test sets.\n- Automatically apply transformations in sequence.\n- **Example:**\n  - Chaining a `StandardScaler` with a `KNeighborsClassifier` model.\n\n::: {#a2f68145 .cell execution_count=9}\n``` {.python .cell-code}\nfrom sklearn.pipeline import make_pipeline\n\npipe_knn = make_pipeline(StandardScaler(), KNeighborsClassifier())\n\n# Correct way to do cross validation without breaking the golden rule. \ncross_val_score(pipe_knn, X_train_toy, y_train_toy) \n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\narray([0.25      , 0.5       , 0.5       , 0.58333333, 0.41666667])\n```\n:::\n:::\n\n\n# [Class demo](https://github.com/UBC-CS/cpsc330-2025W1/blob/main/lectures/102-Varada-lectures/class_demos/demo_05-06-preprocessing.ipynb)\n\n## `sklearn`'s `ColumnTransformer` \n\n- Use ColumnTransformer to build all our transformations together into one object \n\n![](img/column-transformer.png)\n\n- Use a column transformer with sklearn pipelines. \n\n\n## (iClicker) Exercise 6.1\niClicker cloud join link: **https://join.iclicker.com/VYFJ**\n\n**Select all of the following statements which are TRUE.**\n\n- (A) You could carry out cross-validation by passing a `ColumnTransformer` object to `cross_validate`.\n- (B) After applying column transformer, the order of the columns in the transformed data has to be the same as the order of the columns in the original data.\n- (C) After applying a column transformer, the transformed data is always going to be of different shape than the original data.\n- (D) When you call `fit_transform` on a `ColumnTransformer` object, you get a numpy ndarray.\n\n# More preprocessing\n\n## Remarks on preprocessing \n- There is no one-size-fits-all solution in data preprocessing, and decisions often involve a degree of subjectivity. \n  - Exploratory data analysis and domain knowledge inform these decisions\n- Always consider the specific goals of your project when deciding how to encode features. \n\n\n## Alternative methods for scaling\n- [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n  - Good choice when the column follows a normal distribution or a distribution somewhat like a normal distribution.\n- [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html): Transform each feature to a desired range. Appropriate when \n  - Good choice for features such as human age, where there is a fixed range of values and the feature is uniformly distributed across the range\n- [Normalizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html): Works on rows rather than columns. Normalize examples individually to unit norm.\n  - Good choice for frequency-type data \n- [Log scaling](https://scikit-learn.org/stable/modules/preprocessing.html#custom-transformers)\n  - Good choice for features such as ratings per movies (power law distribution; a few movies have lots of ratings but most movies have very few ratings) \n- ...\n\n## Ordinal encoding vs. One-hot encoding\n\n- Ordinal Encoding: Encodes categorical features as an integer array.\n- One-hot Encoding: Creates binary columns for each category‚Äôs presence.\n- Sometimes how we encode a specific feature depends upon the context.  \n\n## Ordinal encoding vs. One-hot encoding\n- Consider **weather** feature and its four categories: Sunny (‚òÄÔ∏è), Cloudy (üå•Ô∏è), Rainy (‚õàÔ∏è), Snowy (‚ùÑÔ∏è)\n- Which encoding would you use in each of the following scenarios? \n  - **Predicting traffic volume** \n  - **Predicting severity of weather-related road incidents** \n\n## Ordinal encoding vs. One-hot encoding\n- Consider **weather** feature and its four categories: Sunny (‚òÄÔ∏è), Cloudy (üå•Ô∏è), Rainy (‚õàÔ∏è), Snowy (‚ùÑÔ∏è)\n- **Predicting traffic volume:** Using one-hot encoding would make sense here because the impact of different weather conditions on traffic volume does not necessarily follow a clear order and different weather conditions could have very distinct effects.\n- **Predicting severity of weather-related road incidents:** An ordinal encoding might be more appropriate if you define your weather categories from least to most severe as this could correlate directly with the likelihood or severity of incidents.\n\n## `handle_unknown = \"ignore\"` of `OneHotEncoder` \n- Use `handle_unknown='ignore'` with `OneHotEncoder` to safely ignore unseen categories during transform.\n- In each of the following scenarios, identify whether it's a reasonable strategy or not. \n  - Example 1: Suppose you are building a model to predict customer behavior (e.g., purchase likelihood) based on features like `location`, `device_type`, and `product_category`. During training, you have observed a set of categories for `product_category`, but in the future, new product categories might be added.\n  - Example 2: You‚Äôre building a model to predict disease diagnosis based on symptoms, where each symptom is categorized (e.g., fever, headache, nausea).\n\n## `handle_unknown = \"ignore\"` of `OneHotEncoder` \n- Reasonable use: When unseen categories are less likely to impact the model's prediction accuracy (e.g., product categories in e-commerce), and you prefer to avoid breaking the model.\n- Not-so-reasonable use: When unseen categories could provide critical new information that could significantly alter predictions (e.g., in medical diagnostics), ignoring them could result in a poor or dangerous outcome.\n\n## `drop=\"if_binary\"` argument of OneHotEncoder\n\n- drop='if_binary' argument in OneHotEncoder:\n- Reduces redundancy by dropping one of the columns if the feature is binary.\n\n## Categorical variables with too many categories\n- Strategies for categorical variables with too many categories:\n  - Dimensionality reduction techniques\n  - Bucketing categories into ‚Äòothers‚Äô\n  - Clustering or grouping categories manually \n  - Only considering top-N categories \n  - ...\n\n## Dealing with text features \n- Preprocessing text to fit into machine learning models using text vectorization.\n- Bag of words representation \n![](img/bag-of-words.png)\n\n## `sklearn` `CountVectorizer`\n- Use `scikit-learn`‚Äôs `CountVectorizer` to encode text data\n- `CountVectorizer`: Transforms text into a matrix of token counts\n- Important parameters:\n  - `max_features`: Control the number of features used in the model \n  - `max_df`, `min_df`: Control document frequency thresholds\n  - `ngram_range`: Defines the range of n-grams to be extracted\n  - `stop_words`: Enables the removal of common words that are typically uninformative in most applications, such as ‚Äúand‚Äù, ‚Äúthe‚Äù, etc.\n\n## Incorporating text features in a machine learning pipeline\n```python\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline\n\ntext_pipeline = make_pipeline(\n    CountVectorizer(),\n    SVC()\n)\n```\n\n# [Class demo](https://github.com/UBC-CS/cpsc330-2024W1/blob/main/lectures/102-Varada-lectures/class_demos/demo_05-06-preprocessing.ipynb)\n\n\n## (iClicker) Exercise 6.2\niClicker cloud join link: **https://join.iclicker.com/VYFJ**\n\nSelect all of the following statements which are TRUE.\n\n- (A) `handle_unknown=\"ignore\"` would treat all unknown categories equally.\n- (B) As you increase the value for `max_features` hyperparameter of `CountVectorizer` the training score is likely to go up.\n- (C) Suppose you are encoding text data using `CountVectorizer`. If you encounter a word in the validation or the test split that's not available in the training data, we'll get an error.\n- (D) In the code below, inside `cross_validate`, each fold might have slightly different number of features (columns) in the fold.\n\n```python\npipe = (CountVectorizer(), SVC())\ncross_validate(pipe, X_train, y_train)\n```\n\n",
    "supporting": [
      "slides-06-column-transformer-text-feats_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}