{
  "hash": "108953c8f5811a3d9501205c60df4c5b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"CPSC 330 Lecture 9: Classification Metrics\" \nauthor: \"Varada Kolhatkar\"\ndescription: \"Metrics for classification\"\ndescription-short: \"confusion metrics, precision, recall, f1-score, PR curves, AP score, ROC curve, ROC AUC, class imbalance\" \nformat:\n  revealjs:\n    embed-resources: true\n    slide-number: true\n    smaller: true\n    center: true\n    logo: img/UBC-CS-logo.png\n    resources:\n      - data/\n      - img/  \n---\n\n\n## Announcements \n\n- Important information about midterm 1\n  - https://piazza.com/class/m01ukubppof625/post/249\n- HW4 has been released. Due next week Monday. \n- HW5 will be released next week Tuesday. It's a project-type assignment and you get till Oct 28th to work on it.  \n\n\n\n## ML workflow \n![](img/ml-workflow.png)\n\n## Accuracy\n- So far we have been measuring model performance using **Accuracy**. \n- **Accuracy** is the proportion of all classifications that were correct, whether *positive* or *negative*. \n$$Accuracy = \\frac{\\text{corrct classifications}}{\\text{total classifications}}$$\n- However, in many real-world applications, the dataset is imbalanced or one kind of mistake is more costly than the other\n- In such cases, it's better to optimize for one of the other metrics instead.\n\n## Fraud Confusion matrix\n\n- Which types of errors would be most critical for the bank to address?\n\n![](img/fraud-confusion-matrix.png)\n\n## Fraud Confusion matrix\n:::: {.columns}\n:::{.column width=\"80%\"}\n![](img/tp-fp-tn-fn-fraud.png)\n:::\n\n:::{.column width=\"20%\"}\n- TN $\\rightarrow$ True negatives \n- FP $\\rightarrow$ False positives \n- FN $\\rightarrow$ False negatives\n- TP $\\rightarrow$ True positives \n:::\n::::\n\n\n## Confusion matrix questions \n\nImagine a spam filter model where emails classified as spam are labeled 1 and non-spam emails are labeled 0. If a spam email is incorrectly classified as non-spam, what is this error called?\n\n- (A) A false positive\n- (B) A true positive\n- (C) A false negative\n- (D) A true negative\n\n## Confusion matrix questions\n\nIn an intrusion detection system, intrusions are identified as 1 and non-intrusive activities as 0. If the system fails to identify an actual intrusion, wrongly categorizing it as non-intrusive, what is this type of error called?\n\n- (A) A false positive\n- (B) A true positive\n- (C) A false negative\n- (D) A true negative\n\n## Confusion matrix questions\n\nIn a medical test for a disease, diseased states are labeled as 1 and healthy states as 0. If a healthy patient is incorrectly diagnosed with the disease, what is this error known as?\n\n- (A) A false positive\n- (B) A true positive\n- (C) A false negative\n- (D) A true negative\n\n\n## Precision, Recall, F1-Score\n![](img/precision-recall.png)\n![](img/fraud-precision-recall.png)\n\n## iClicker Exercise 9.1\n\n**iClicker cloud join link: https://join.iclicker.com/VYFJ**\n\n**Select all of the following statements which are TRUE.**\n\n- (A) In medical diagnosis, false positives are more damaging than false negatives (assume \"positive\" means the person has a disease, \"negative\" means they don't).\n- (B) In spam classification, false positives are more damaging than false negatives (assume \"positive\" means the email is spam, \"negative\" means they it's not).\n- (C) If method A gets a higher accuracy than method B, that means its precision is also higher.\n- (D) If method A gets a higher accuracy than method B, that means its recall is also higher.\n\n## Counter examples\n\nMethod A - higher accuracy but lower precision\n\n| Negative | Positive\n| -------- |:-------------:|\n| 90      | 5|\n| 5      | 0|\n\nMethod B - lower accuracy but higher precision\n\n| Negative | Positive\n| -------- |:-------------:|\n| 80      | 15|\n| 0      | 5|\n\n## Thresholding \n\n- The above metrics assume a fixed threshold. \n- We use thresholding to get the binary prediction. \n- A typical threshold is 0.5.\n    - A prediction of 0.90 $\\rightarrow$ a high likelihood that the transaction is fraudulent and we predict **fraud**\n    - A prediction of 0.20 $\\rightarrow$ a low likelihood that the transaction is non-fraudulent and we predict **Non fraud**\n- **What happens if the predicted score is equal to the chosen threshold?**\n\n- [Play with classification thresholds](https://developers.google.com/machine-learning/crash-course/classification/thresholding)\n\n\n## iClicker Exercise 9.2\n\n**iClicker cloud join link: https://join.iclicker.com/VYFJ**\n\n**Select all of the following statements which are TRUE.**\n\n- (A) If we increase the classification threshold, both true and false positives are likely to decrease.\n- (B) If we increase the classification threshold, both true and false negatives are likely to decrease.\n- (C) Lowering the classification threshold generally increases the modelâ€™s recall.  \n- (D) Raising the classification threshold can improve the precision of the model if it effectively reduces the number of false positives without significantly affecting true positives.\n\n\n## PR curve\n- Calculate precision and recall (TPR) at every possible threshold and graph them. \n- Better choice for highly imbalanced datasets \n\n![](img/pr-curve-example.png)\n\n\n\n## ROC curve \n- Calculate the true positive rate (TPR) and false positive rate (FPR) at every possible thresholding and graph TPR over FPR. \n- Good choice when the datasets are roughly balanced. \n![](img/roc-curve-example.png)\n\n## AUC \n- The area under the ROC curve (AUC) represents the probability that the model, if given a randomly chosen positive and negative example, will rank the positive higher than the negative.\n\n\n## ROC AUC questions\n\nConsider the points A, B, and C in the following diagram, each representing a threshold. Which threshold would you pick in each scenario?\n\n:::: {.columns}\n\n:::{.column width=\"50%\"}\n![](img/auc_abc)\n:::\n\n:::{.column width=\"50%\"}\n\n- (A) If false positives (false alarms) are highly costly\n- (B) If false positives are cheap and false negatives (missed true positives) highly costly\n- (C) If the costs are roughly equivalent\n:::\n::::\n\n[Source](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)\n\n",
    "supporting": [
      "slides-09-classification-metrics_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}