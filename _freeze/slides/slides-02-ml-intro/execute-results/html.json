{
  "hash": "9cc50053937f7263ef4a8fea012dfc8d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Introduction to Machine Learning\"\nauthor: \"Varada Kolhatkar\"\nformat: \n    revealjs:\n      smaller: true\n      center: true\n---\n\n\n## Introduction to Machine Learning\n\\\nMachine Learning uses computer programs to digest and accurately model data. After *training* on the data, a program can be used to extract hidden patterns, make predictions in new situations or generate novel content.\n\nThe program learns based on the *features* present in the data, which represent the information we have about each example.\n\n## Introduction to Machine Learning\n\\ \n\n![](img/sup-ML-terminology.png)\n\n\n## Activity 1\n\\\nWrite one (or several) problems in your research field where you think Machine Learning could be applied. Try to address the following questions:\n\n* What goal are you trying to accomplish? What would an ideal solution to your problem look like?\n* How would a human solve this problem? What approaches are presently available and utilized?\n* What kind of data is available to you, or might be collected? What features are present in the data?\n\nOne of the learning objectives of the workshop will be to determine whether your goal is best addressed using supervised machine learning, inferential statistics, unsupervised learning, deep learning, generative AI, or a non-ML solution.\n\n## Classification vs. Regression\n\\\n\n![](img/classification-vs-regression.png)\n\n## Measuring Performance\n\\\n\n* Performance on classification tasks can be measured based on the *accuracy* of the model's predictions.\n\n* Performance on a regression task can be measured based on *error*. Mean squared error is one choice, but there are many others!\n\n\n## Inference vs. Prediction\n\\\n\n* *Inference* is the use of a model to infer a relationship between features (independent variables) and targets (independent variables).\n\n* *Prediction* is the use of a model to predict the target value for a new example not seen in training.\n\n## What outcome do we care about?\n\\\n\n* A researcher studying the impact of pollution on cancer risk is performing *inference*. They may not make perfect predictions (since the dataset is likely to be noisy) but good statistical inference could be extremely valuable.\n\n* Gmail's spam filtering algorithm is performing *prediction*. We are not really trying to improve human understanding of what makes a message spam (often it is obvious), we just want a model that makes good predictions.\n\n* Of course, these goals are related, so in many situations we may be interested in both.\n\n\n## Example: Linear Regression\n\\\n![](img/visualization.png)\n\nIs this inference or prediction?\n\n## Types of Machine Learning\n\\\nToday we will see two main types of machine learning, namely\n\n* Supervised Learning, and\n\n* Unsupervised Learning.\n\nWe will also discuss which problems each type might be best suited for.\n\n## Supervised Learning\n\\\nHere the training data is comprised of a set of *features*, and each example comes with a corresponding *target*. The goal is to get a machine learning model to accurately predict the target based on the feature values.\n\nExamples could include spam filtering, face recognition or weather forecasting.\n\n## Unsupervised Learning\n\\\nIn unsupervised learning, there are no targets. The goal is instead to uncover underlying patterns. These can be used to provide a concise summary of the data, or group similar examples together.\n\nExamples could include customer segmentation, anomaly detection or online recommendation systems (think Netflix).\n\n## Other ML types\n\\\nSome other types of Machine Learning include self-supervised learning and reinforcement learning.\n\nSelf-supervised algorithms automatically learn to generate labels and transform unsupervised problems to supervised ones.\n\nReinforcement Leaning trains an agent using a system of rewards and penalties. The agent learns strategies to maximize reward. AlphaGo is a reinforcement learning agent that taught itself to play Go, and was able to beat the strongest human Go players.\n\n## Activity 2\n\\ \n\nReturn to the problems you identified in Activity 1. Try to decide if they involve performing inference or prediction.\n\nAlso suggest whether you think they are best approached with supervised or unsupervised learning. What aspects of the problem particularly suggest one approach over another?\n\n## A Simple Supervised Learning Model\n\\\nWe will use a simple machine learning model-- a decision tree-- to demonstrate some fundamental concepts in machine learning. Suppose we have the following dataset:\\\n\n::: {#4ebac668 .cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ml_experience</th>\n      <th>class_attendance</th>\n      <th>lab1</th>\n      <th>lab2</th>\n      <th>lab3</th>\n      <th>lab4</th>\n      <th>quiz1</th>\n      <th>quiz2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>92</td>\n      <td>93</td>\n      <td>84</td>\n      <td>91</td>\n      <td>92</td>\n      <td>A+</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>94</td>\n      <td>90</td>\n      <td>80</td>\n      <td>83</td>\n      <td>91</td>\n      <td>not A+</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>78</td>\n      <td>85</td>\n      <td>83</td>\n      <td>80</td>\n      <td>80</td>\n      <td>not A+</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>91</td>\n      <td>94</td>\n      <td>92</td>\n      <td>91</td>\n      <td>89</td>\n      <td>A+</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>77</td>\n      <td>83</td>\n      <td>90</td>\n      <td>92</td>\n      <td>85</td>\n      <td>A+</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n\\ \nHow would you go about predicting the Quiz 2 grade?\n\n## Decision Trees\n\\\nA decision tree iteratively splits the data by asking questions about feature values.\n\nThe algorithm tries to ask questions that best separate one class from another. It's like a game of twenty questions!\n\n## A Decision Stump\n\\\n\n::: {#05f00e9d .cell execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![](slides-02-ml-intro_files/figure-revealjs/cell-3-output-1.png){width=763 height=389}\n:::\n:::\n\n\nWe could start by splitting the data based on the students' Lab 3 grades.\n\n## Iterating the procedure\n\\ \n\n::: {#5e64cd65 .cell execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![](slides-02-ml-intro_files/figure-revealjs/cell-4-output-1.png){width=763 height=389}\n:::\n:::\n\n\nThen we further split each of the resulting nodes, again asking questions involving features in the dataset.\n\n## Building a Decision Tree\n\\ \n\n::: {#4970b343 .cell execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![](slides-02-ml-intro_files/figure-revealjs/cell-5-output-1.png){width=763 height=389}\n:::\n:::\n\n\n## Decision Boundary\n\\\nThe first two questions in our tree involved Lab 3 and Quiz 1 grades. We can make a plot involving these two features to better understand our tree.\n\n![](img/dbound.png)\n\n\n\n## Model Parameters\n\\\n\nDuring training, the model decides which feature to use to split at each node. It also decides which value of the feature to split at. This is the 'learning' phase, where the algorithm is trying different options and selecting the 'best' feature and value for splitting.\n\n\n## Hyperparameters\n\\\nThe maximum depth of a decision tree (at most how many questions it asks) is a *hyper-parameter* of the model. We can build different trees to test which choice of hyper-parameter gives the best result.\n\nSome models may have a continuous range of options for a given hyper-parameter. This gives rise to a potentially infinite choice of \"models\" to test.\n\n## Trying to Recognize Faces\n\\\nTo demonstrate some fundamental concepts in machine learning, we will attempt to biuld a decision tree that can recognize faces. Our data will be taken from the Olivetti Faces dataset, which is a collection of 400 images of faces.\n\nThe labels correspond to the forty individuals that are pictured, and the dataset contains 10 photos per individual. We will try to use a decision tree to correctly predict the individual for each photo.\n\n## A Look at the Data\n\\\nEach photo is 64x64 pixels in grayscale. The images are represented by a row of pixel intensities showing how dark each individual pixel should be.\n\n::: {#cf4d806a .cell execution_count=5}\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>...</th>\n      <th>4092</th>\n      <th>4093</th>\n      <th>4094</th>\n      <th>4095</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.309917</td>\n      <td>0.367769</td>\n      <td>0.417355</td>\n      <td>0.442149</td>\n      <td>...</td>\n      <td>0.148760</td>\n      <td>0.152893</td>\n      <td>0.161157</td>\n      <td>0.157025</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.454545</td>\n      <td>0.471074</td>\n      <td>0.512397</td>\n      <td>0.557851</td>\n      <td>...</td>\n      <td>0.152893</td>\n      <td>0.152893</td>\n      <td>0.152893</td>\n      <td>0.152893</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.318182</td>\n      <td>0.400826</td>\n      <td>0.491736</td>\n      <td>0.528926</td>\n      <td>...</td>\n      <td>0.144628</td>\n      <td>0.140496</td>\n      <td>0.148760</td>\n      <td>0.152893</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>0.500000</td>\n      <td>0.533058</td>\n      <td>0.607438</td>\n      <td>0.628099</td>\n      <td>...</td>\n      <td>0.157025</td>\n      <td>0.177686</td>\n      <td>0.148760</td>\n      <td>0.190083</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>0.214876</td>\n      <td>0.219008</td>\n      <td>0.219008</td>\n      <td>0.223140</td>\n      <td>...</td>\n      <td>0.545455</td>\n      <td>0.574380</td>\n      <td>0.590909</td>\n      <td>0.603306</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>0.516529</td>\n      <td>0.462810</td>\n      <td>0.280992</td>\n      <td>0.252066</td>\n      <td>...</td>\n      <td>0.322314</td>\n      <td>0.359504</td>\n      <td>0.355372</td>\n      <td>0.384298</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 4096 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#9c3ced29 .cell execution_count=6}\n\n::: {.cell-output .cell-output-stdout}\n```\nThe dataset has 4096 features.\n```\n:::\n:::\n\n\n## A Decision Tree Classifier\n\\\nWe can build a decision tree classifier on the dataset of faces and see how it performs. For now we will train on a random subset of the data that contains 80% of the images (we'll explain why later)\n\nLet's see how accurate this model gets after training.\n\n## A Decision Tree Classifier\n\\\n\n::: {#e1fbf6d0 .cell execution_count=7}\n\n::: {.cell-output .cell-output-stdout}\n```\nThe model classified 100.0% of training examples correctly by \n building a decision tree of depth 38\n```\n:::\n:::\n\n\n\\\nThat's very accurate indeed! Maybe decision trees are a really good way to detect and classify faces.\n\nRemember, we only trained on 80% of the data. Let's see how our model performs on the remaining 20%\n\n## Did we build a good model?\n\\\n\n::: {#04bf7f0b .cell execution_count=8}\n\n::: {.cell-output .cell-output-stdout}\n```\nThe model acheived an accuracy of 47.5% on new data\n```\n:::\n:::\n\n\n\\\n...oops.\n\n## What's going on?\n\n::: {#37045993 .cell execution_count=9}\n\n::: {.cell-output .cell-output-display}\n![](slides-02-ml-intro_files/figure-revealjs/cell-10-output-1.png){width=794 height=429}\n:::\n:::\n\n\n## Practice makes perfect\n\\\nOur deep decision tree likely just memorized the dataset. After all, with a tree of depth 38, we could actually memorize up to 2^38^ distinct examples!\n\nClearly this does not make for a good model. After all, we want a model that can recognize faces, even when they appear in new images.\n\n## Overfitting\n\\\n*Overfitting* refers to a situation where the model learns noise from the training data, leading to a poor performance when deployed on new data.\n\nComplex models are prone to overfitting-- we cannot just rely on training error to measure their performance. Simple models typically have similar train and test errors, but both will be high.\n\n## \n\nThus we have our \"fundamental tradeoff\": as we increase model complexity, the training error will reduce but the gap between training and test error will increase.\n\n##\n\n![](img/spot.png){fig-align=\"center\"}\n\n## Scenario 1\n\\\nYour colleague is trying to build a machine learning model to detect cancers in medical imaging. They know about overfitting, so they separate their data into a training set and a test set.\n\nThey use 10 different types of machine learning models, and try 1000 different combinations of hyper-parameters for each. In every case, they only use the training set to train their model, and then note how the model performs by measure accuracy on the test set.\n\nThe best model achieves 99% accuracy on the test set. Your colleague tells you they have found a machine learning model that diagnoses cancer with 99% accuracy.\n\n**Do you believe them?**\n\n## The Golden Rule of Machine Learning\n\\\nBy using the same test set for each of the 10,000 models they tried, your colleague has violated the *golden rule of machine learning*.\n\nThe golden rule tells us that **test data must not influence the model training in any way**.\n\nEven though your colleague never directly trained on test data, they used test data multiple times to validate model performance. As a result, they are likely to have found good performance *purely by accident*.\n\n## Scenario 2\n\\\nYour colleague now separates their data into a training set, a validation set *and* a test set.\n\nThey again use 10 types of models and try 1000 combinations of hyper-parameters for each. They use the training set to train their model, and then note how the model performs by measure accuracy on the *validation* set.\n\nThe best model achieves 99% accuracy on the validation set, after which it is used on the test set. It achieves 99% accuracy again.\n\n**Do you trust the outcome now?**\n\n",
    "supporting": [
      "slides-02-ml-intro_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}