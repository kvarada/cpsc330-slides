---
title: "CPSC 330 Lecture 10: Regression Metrics" 
author: "Varada Kolhatkar"
description: "Metrics for Regression"
description-short: "Ridge, " 
format:
  revealjs:
    html-math-method: mathjax
    embed-resources: true
    slide-number: true
    smaller: true
    center: true
    logo: img/UBC-CS-logo.png
    resources:
      - data/
      - img/  
---

## Announcements 

## Recap: Confusion matrix
:::: {.columns}
:::{.column width="80%"}
![](img/tp-fp-tn-fn-fraud.png)
:::

:::{.column width="20%"}
- TN $\rightarrow$ True negatives 
- FP $\rightarrow$ False positives 
- FN $\rightarrow$ False negatives
- TP $\rightarrow$ True positives 
:::
::::

## Recap: Precision, Recall, F1-Score
:::: {.columns}
:::{.column width="70%"}
![](img/fraud-precision-recall.png)
:::
:::{.column width="30%"}
$$ f1 = 2 \times \frac{ precision \times recall}{precision + recall}$$
:::
::::

## Recap: PR curve
- Calculate precision and recall (TPR) at every possible threshold and graph them. 
- Better choice for highly imbalanced datasets because it focuses on the performance of the positive class. 

![](img/pr-curve-example.png)


## Questions for you 

- What's the difference between the average precision (AP) score and F1-score? 
- Which model would you pick? 

![](img/pr-curve-which-model.png)

## Recap: ROC curve 
- Calculate the true positive rate (TPR) and false positive rate (FPR) ($\frac{FP}{FP + TN}$) at every possible thresholding and graph TPR over FPR. 
- Good choice when the datasets are roughly balanced. 
![](img/roc-example.png)
![](img/roc-curve-example.png)

## Recap: ROC Curve 
- Not a great choice when there is an extreme imbalance because FPR can remain relatively low even if the number of false positives is high, simply because the number of negatives is very large.  
$$ FPR  = \frac{FP}{FP + TN}$$ 
- The area under the ROC curve (AUC) represents the probability that the model, if given a randomly chosen positive and negative example, will rank the positive higher than the negative.

## Questions for you {.smaller}
:::: {.columns}
:::{.column width="60%"}
![](img/roc-baseline.png) 
:::
:::{.column width="40%"}
- What's the AUC of a baseline model? 
:::
::::

[Source](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)

## Questions for you {.smaller}

:::: {.columns}
:::{.column width="60%"}
![](img/roc-curve-which-model.png)
:::
:::{.column width="40%"}
- Which model would you pick? 
:::
::::

## Dealing with class imbalance
- Under sampling 
- Oversampling 
- `class weight="balanced"` (preferred method for this course)
- SMOTE

# [Classification metrics class demo](https://github.com/UBC-CS/cpsc330-2024W1/blob/main/lectures/102-Varada-lectures/class_demos/demo_09-classification-metrics.ipynb)

# [Regression metrics class demo](https://github.com/UBC-CS/cpsc330-2024W1/blob/main/lectures/102-Varada-lectures/class_demos/demo_10-regression-metrics.ipynb)

## Ridge and RidgeCV
- **Ridge Regression**: `alpha` hyperparameter controls model complexity.
- **RidgeCV**: Ridge regression with built-in cross-validation to find the optimal `alpha`.

## `alpha` hyperparameter
- **Role of `alpha`**:
  - Controls model complexity
  - Higher `alpha`: Simpler model, smaller coefficients.
  - Lower `alpha`: Complex model, larger coefficients.

## Regression metrics: MSE, RMSE, MAPE

- **Mean Squared Error (MSE)**: Average of the squares of the errors.
- **Root Mean Squared Error (RMSE)**: Square root of MSE, same units as the target variable.
- **Mean Absolute Percentage Error (MAPE)**: Average of the absolute percentage errors.

## Applying log transformation to the targets

- Suitable when the target has a wide range and spans several orders of magnitude 
  - Example: counts data such as social media likes or price data
- Helps manage skewed data, making patterns more apparent and regression models more effective.
- `TransformedTargetRegressor`
  - Wraps a regression model and applies a transformation to the target values.


## iClicker Exercise 10.1

**Select all of the following statements which are TRUE.**

- (A) Price per square foot would be a good feature to add in our `X`. 
- (B) The `alpha` hyperparameter of `Ridge` has similar interpretation of `C` hyperparameter of `LogisticRegression`; higher `alpha` means more complex model. 
- (C) In `Ridge`, smaller alpha means bigger coefficients whereas bigger alpha means smaller coefficients.  


## iClicker Exercise 10.2

**Select all of the following statements which are TRUE.**

- (A) We can use still use precision and recall for regression problems but now we have other metrics we can use as well.
- (B) In `sklearn` for regression problems, using `r2_score()` and `.score()` (with default values) will produce the same results.
- (C) RMSE is always going to be non-negative.
- (D) MSE does not directly provide the information about whether the model is underpredicting or overpredicting.
- (E) We can pass multiple scoring metrics to `GridSearchCV` or `RandomizedSearchCV` for regression as well as classification problems. 
