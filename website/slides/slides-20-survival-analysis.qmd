---
title: "CPSC 330 Lecture 20: Survival analysis"
author: "Varada Kolhatkar"
format: 
    revealjs:
      html-math-method: mathjax    
      embed-resources: true
      slide-number: true
      logo: img/UBC-CS-logo.png
      resources:
        - data/
        - img/        
---

```{python}
import os
import sys

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer, make_column_transformer
from sklearn.dummy import DummyClassifier
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression, Ridge
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import (
    cross_val_predict,
    cross_val_score,
    cross_validate,
    train_test_split,
)
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.preprocessing import (
    FunctionTransformer,
    OneHotEncoder,
    OrdinalEncoder,
    StandardScaler,
)

sys.path.append(os.path.join(os.path.abspath("."), "code"))
from utils import *

plt.rcParams["font.size"] = 12

import warnings

warnings.filterwarnings("default")
DATA_DIR = os.path.join(os.path.abspath("."), "data/")
```

## Focus on the breath!

![](img/inukshuk.jpeg){.nostretch fig-align="center" width="500px"}

## Announcements

- HW9 has been released (due next week Monday)
  - Almost there! Youâ€™ve got this! ðŸ˜Š
- Midterm 2 grades were released last week. 

## Recap: iClicker questions {.smaller}
### (iClicker) Exercise 20.1 

**Select all of the following statements which are TRUE.**

- (A) We need to be careful when splitting the data when working with time series data.
- (B) Cross-validation in time series can be randomly applied like in other machine learning tasks.
- (C) In time series forecasting, the future value of a series can only be predicted based on its past values and cannot incorporate other variables.
- (D) When we used `RandomForestRegressor` model on the POSIX time feature, it predicted a straight line on the test data because tree-based models are inherently unable to extrapolate (i.e., make predictions outside the range of the training data).


## Customer churn 

Customer churn, also known as customer attrition, refers to the phenomenon where customers or subscribers stop doing business with a company or service.

## Monthly subscriber churn rates for various streaming services

:::: {.columns}
:::{.column width="50%"}
![](img/subscriber-churn.png)
[Source](https://sherwood.news/tech/could-mergers-help-streaming-sites-turn-the-churning-tides/)
::: 

:::{.column width="50%"}

**Question:** Is a smaller or a larger churn rate more desirable for a subscription-based company?

- A smaller churn rate is better (means fewer customers leaving)
- Lower churn = higher customer retention = more stable revenue

:::
::::

## The challenge: Predicting *when*, not just *whether*

Imagine you work for a subscription-based telecom company.

- Your team wants to predict **when a customer will churn**, not just whether they churn.
- This helps the company:
  - Target retention strategies at the right time
  - Allocate resources efficiently to high-risk customers
  - Understand which factors accelerate or delay churn
- Our goal: **model time to churn** while accounting for customers who haven't churned yet.

## [Customer Churn Dataset](https://www.kaggle.com/blastchar/telco-customer-churn) {.scrollable .smaller}

If you wanted to predict whether a customer churns, what kind of model from your ML toolbox would you use?

```{python}
df = pd.read_csv(DATA_DIR + "WA_Fn-UseC_-Telco-Customer-Churn.csv")
train_df, test_df = train_test_split(df, random_state=123)
train_df.head()
```
## Churn prediction as binary classification

- When we treat churn as a binary classification problem, we only ask: **Has the customer churned by the time of data collection?**

- Limitations of this approach:
  - Answers only "Yes/No" and discards **when** churn occurred
  - Treats a customer who churned after 1 month the same as one who churned after 5 years
  - Ignores the time dimension entirely

- **Is that what we want?** Not if timing matters for business decisions! 

## Predicting tenure

:::: {.columns}
:::{.column width="30%"}
```{python}
train_df[["tenure"]].head()
```
:::
:::{.column width="70%"}

In our dataset, the tenure column is the number of months the customer has stayed with the company. Can we use the techniques you learned so far (e.g., regression models) to predict the time (tenure in our case)? 
:::
::::

## The problem: Incomplete information

:::: {.columns}
:::{.column width="30%"}
```{python}
train_df[["tenure"]].head(8)
```
:::
:::{.column width="70%"}
- We only have information about tenure **up to the point we collected the data**. 
- For customers who haven't churned:
  - We don't know their true "time to churn"
  - We only know they lasted **at least** this long
  - Their actual churn time is unknown (incomplete information)
- This is called **right-censoring** - the event hasn't occurred yet
:::
::::

## Types of censoring

![](img/censoring.png)

- **Right-censoring**: Event hasn't occurred yet (most common in practice)
- **Left-censoring**: Event occurred before observation started
- **Interval-censoring**: Event occurred within a time interval

## Time to event and censoring

:::: {.columns}
:::{.column width="30%"}
```{python}
train_df[["tenure"]].head(8)
```
:::
:::{.column width="70%"}
- Many customers in the dataset are still active (Churn = "No"). 
- They are **right-censored**: we only know their tenure **so far**, not their final tenure. 
- **Key insight**: Ignoring or removing censored cases will bias our estimates:
  - We'd only learn from customers who churned
  - This underestimates true survival times
:::
::::


## Time-to-event problems

Time-to-event problems appear everywhere. Examples include:

- Time until a customer leaves a subscription service
- Time until a disease causes death
- Time until equipment fails
- Duration of unemployment until finding a job
- Waiting time until a scheduled surgery

These all follow the same pattern: the event happens once, and we care about how long it takes.


# Approaches 

## Approach 1: Only use churned customers â›”ï¸

Suppose we only consider rows where Churn == "Yes" and throw away all right-censored customers. 

```{python}
train_df_churn = train_df.query(
    "Churn == 'Yes'"
)  # Consider only examples where the customers churned.
test_df_churn = test_df.query(
    "Churn == 'Yes'"
)  # Consider only examples where the customers churned.
train_df_churn.head(4)
```

**Problem**: This throws away valuable information from active customers!

## iClicker 

Would only considering rows where Churn == "Yes" and throwing away all right-censored customers overestimate or underestimate the average survival time?
- (A) Overestimate 
- (B) Underestimate 
- (C) Cannot tell based on the provided information

**Explanation**: We only see customers who churned (typically shorter tenures). Active customers with longer tenures are excluded, so we underestimate true survival time.

## Approach 2: Assume everyone churns now â›”ï¸

Treat all current tenure values as final, even for active customers.

```{python}
train_df[["tenure", "Churn"]].head()
```

**Problem**: This assumes active customers (Churn = "No") will churn immediately, which underestimates their true survival time.

## iClicker 

Would assuming everyone churns now underestimate or overestimate tenure?
- (A) Overestimate 
- (B) Underestimate 
- (C) Cannot tell based on the provided information

**Explanation**: Active customers will likely stay longer, but we're treating their current tenure as final. This underestimates their true time to churn.

## Approach 3: Survival analysis âœ…

Survival analysis explicitly models time until an event **and properly handles censoring**.

**Common methods:**

- **Kaplanâ€“Meier estimator**: Non-parametric method for estimating survival curves
- **Cox proportional hazards model**: Semi-parametric regression model for survival data
- **Survival forests**: Random forest variant adapted for censored data

These methods allow estimation of:

- **Survival function**: $S(t) = P(T > t)$ (probability of surviving past time $t$)
- **Hazard function**: $h(t)$ (instantaneous risk of the event at time $t$)

# [Class demo](https://github.com/UBC-CS/cpsc330-2025W1/blob/main/lectures/102-Varada-lectures/class_demos/demo_20-survival-analysis.ipynb) 


