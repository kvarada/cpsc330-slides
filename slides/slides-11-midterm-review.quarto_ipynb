{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: 'CPSC 330 Lecture 11: Midterm review'\n",
        "description: Review of the concepts learned so far \n",
        "\n",
        "format:\n",
        "    revealjs:\n",
        "        html-math-method: plain\n",
        "        slide-number: true\n",
        "        slide-level: 2\n",
        "        theme:\n",
        "          - slides.scss\n",
        "        center: true\n",
        "        logo: img/mds-hex-sticker.png\n",
        "        resources:\n",
        "          - data/\n",
        "          - img/\n",
        "\n",
        "\n",
        "editor:\n",
        "  render-on-save: true\n",
        "---\n",
        "\n",
        "\n",
        "## Announcements \n",
        "\n",
        "- Our midterm is coming up! Important information about midterm 1\n",
        "  - https://piazza.com/class/m01ukubppof625/post/249\n",
        "  - **Good news for you: You'll have access to our course notes in the midterm!**\n",
        "- Make use of the office hours and tutorials. I've my OH from 2 to 3 today.\n"
      ],
      "id": "9f765bd7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(os.path.join(os.path.abspath(\".\"), \"code\"))\n",
        "from plotting_functions import *\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "plt.rcParams[\"font.size\"] = 16\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "%matplotlib inline\n",
        "\n",
        "DATA_DIR = 'data/' "
      ],
      "id": "832785bd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is machine learning \n",
        "- ML uses data to build models that identify patterns, make predictions, or generate content.\n",
        "- It enables computers to learn from data.\n",
        "- No single model is suitable for all situations.\n",
        "\n",
        "## When is ML suitable?\n",
        "\n",
        "- ML excels when the problem involve identifying complex patterns or relationships in large datasets that are difficult for humans to discern manually.\n",
        "- Rule-based systems are suitable where clear and deterministic rules can be defined. Good for structured decision making. \n",
        "- Human experts are good with problems which require deep contextual understanding, ethical judgment, creative input, or emotional intelligence.\n",
        "\n",
        "## Terminology\n",
        "- Features (`X`) and target (`y`)\n",
        "- Examples\n",
        "- Predictions\n",
        "- Accuracy, error\n",
        "- Parameters and hyperparameters\n",
        "- Decision boundaries\n",
        "\n",
        "# ML fundamentals \n",
        "## Important concepts \n",
        "- Why do we split the data? What are train/valid/test splits? \n",
        "- What are the benefits of cross-validation?\n",
        "- What is underfitting and overfitting? \n",
        "- What’s the fundamental trade-off in supervised machine learning?\n",
        "- What is the golden rule of machine learning? \n",
        "\n",
        "## Overfitting and underfitting {.smaller}\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"60%\"}\n",
        "![](img/underfit-overfit-google-developer.png)\n",
        "\n",
        "[Source](https://developers.google.com/machine-learning/crash-course/overfitting/overfitting)\n",
        ":::\n",
        "\n",
        "::: {.column width=\"40%\"}\n",
        "- An **overfit model** matches the training set so closely that it fails to make correct predictions on new unseen data.  \n",
        "- An **underfit model** is too simple and does not even make good predictions on the training data \n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "## The fundamental tradeoff {.smaller}\n",
        "\n",
        "- As you increase the model complexity, training score tends to go up and the gap between train and validation scores tends to go up.  \n",
        "- How to pick a model? \n",
        "![](img/malp_0201.png){fig-align=\"center\"}\n",
        "\n",
        "# Models\n",
        "## Supervised models we have seen \n",
        "\n",
        "- Decision trees: Split data into subsets based on feature values to create decision rules \n",
        "- $k$-NNs: Classify based on the majority vote from $k$ nearest neighbors\n",
        "- SVM RBFs: Create a boundary using an RBF kernel to separate classes\n",
        "- Linear models: Assumption that the relationship between `X` and `y` is linear \n",
        "\n",
        "## Comparison of models \n",
        "| **Model**        | Parameters/hyperparameters | **Strengths**  | **Weaknesses**     |\n",
        "|------------------|--------------------------------|---------------------------|---------------------------|\n",
        "| **Decision Trees**               |  |  |  |\n",
        "| **KNNs**              |  |  |  |\n",
        "| **SVM RBF**            |  |  |  |\n",
        "| **Linear models**         |  |  | | \n",
        "\n",
        "\n",
        "# Transformers \n",
        "\n",
        "## `sklearn` Transformers \n",
        "| **Transformer**        | Hyperparameters | **When to use?** |\n",
        "|------------------|--------------------------------|---------------------------|\n",
        "| `SimpleImputer`  |  |  | \n",
        "| `StandardScaler`              |  |  | \n",
        "| `OneHotEncoder`            |  |  | \n",
        "| `OrdinalEncoder`         |  |  | \n",
        "| `CountVectorizer`        |  |  | \n",
        "| `TransformedTargetRegressor` | | |\n",
        "\n",
        "\n",
        "# Data leakage \n",
        "\n",
        "## Features\n",
        "\n",
        "- Using features that are directly related to the target can cause data leakage. \n",
        "  - Example: If you’re building a model to predict the churn rate of customers in a subscription service (churned or not churned) and you are using a feature like “account deactivation date”.  \n",
        "- If a feature essentially gives away the answer, the model might perform exceptionally well during training but fail to generalize to new, unseen data.\n",
        "\n",
        "## Preprocessing\n",
        "- Incorporating information from the validation or test data during the preprocessing phase (e.g., scaling based on the distribution of the entire dataset instead of just the training set) can also lead to leakage. This can happen if the transformations applied to the training data are influenced by the whole dataset, thus indirectly feeding information about the test set into the model during training.\n",
        "\n",
        "# Preprocessing with data leakage \n",
        "\n",
        "## Pipelines \n",
        "- Pipeline is a way to chain multiple steps (e.g., preprocessing + model fitting) into a single workflow.\n",
        "- Simplify the code and improves readability.\n",
        "- Reduce the risk of data leakage by ensuring proper transformation of the training and test sets.\n",
        "- Automatically apply transformations in sequence.\n",
        "\n",
        "## Pipelines example \n",
        "- **Example:**\n",
        "  - Chaining a `StandardScaler` with a `KNeighborsClassifier` model.\n"
      ],
      "id": "76f63300"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: true\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipe_knn = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
        "\n",
        "# Correct way to do cross validation without breaking the golden rule. \n",
        "cross_val_score(pipe_knn, X_train, y_train) "
      ],
      "id": "ac88f11e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Column Transformers\n",
        "- In what scenarios do we use column transformers? \n",
        "  - Different transformations for different types of columns (e.g., scaling numerical data, encoding categorical data).\n",
        "- Handle datasets with heterogeneous data types effectively.\n",
        "\n",
        "## Hyperparameter Optimization \n",
        "| **Method**        | Strengths/Weaknesses | **When to use?** |\n",
        "|------------------|--------------------------------|---------------------------|\n",
        "| Nested for loops |  |  | \n",
        "| Grid search  |  |  | \n",
        "| Random search  |  |  | \n",
        "\n",
        "## Classification Metrics\n",
        "| **Metric**        | How to generate/calculate? | **When to use?** |\n",
        "|------------------|--------------------------------|---------------------------|\n",
        "| Accuracy  |  |  | \n",
        "| Precision              |  |  | \n",
        "| Recall          |  |  | \n",
        "| F1-score         |  |  | \n",
        "| PR curve/AP score        |  |  | \n",
        "| ROC curve/AUC        |  |  | \n",
        "\n",
        "\n",
        "## Classification Metrics\n",
        "| **Metric**        | How to generate/calculate? | **When to use?** |\n",
        "|------------------|--------------------------------|---------------------------|\n",
        "| MSE  |  |  | \n",
        "| RMSE              |  |  | \n",
        "| r2 score          |  |  | \n",
        "| MAPE         |  |  | \n"
      ],
      "id": "9d3ad3ab"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/kvarada/miniforge3/envs/cpsc330/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}